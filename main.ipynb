{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.classify import NaiveBayesClassifier, accuracy\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import string\n",
    "import random\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enter_to_continue():\n",
    "    input(\"Press Enter to continue...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = None\n",
    "review = \"\"\n",
    "category = \"\"\n",
    "\n",
    "def load_dataset():\n",
    "    df = pd.read_csv('movie-review-cleaned.csv')\n",
    "    return df\n",
    "\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return 'a'\n",
    "    elif tag.startswith('V'):\n",
    "        return 'v'\n",
    "    elif tag.startswith('N'):\n",
    "        return 'n'\n",
    "    elif tag.startswith('R'):\n",
    "        return 'r'\n",
    "    else:\n",
    "        return 'n'\n",
    "\n",
    "def preprocess_words(words):\n",
    "    words = [word for word in words if word.lower() not in stopwords.words('english')]\n",
    "    words = [word for word in words if word.lower() not in string.punctuation]\n",
    "    words = [word for word in words if word.isalpha()]\n",
    "\n",
    "    word_tag = pos_tag(words)\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word, pos=get_wordnet_pos(tag)) for word, tag in word_tag]\n",
    "\n",
    "    stemmer = PorterStemmer()\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "    return words\n",
    "\n",
    "def train_model():\n",
    "    df = load_dataset().sample(n=3000)\n",
    "\n",
    "    reviews = [str(review) for review in df['review'].to_list()]\n",
    "    sentiments = [str(sentiment) for sentiment in df['sentimentScore'].to_list()]\n",
    "\n",
    "    word_list = []\n",
    "\n",
    "    for sentence in reviews:\n",
    "        words = word_tokenize(sentence)\n",
    "\n",
    "        for word in words:\n",
    "            word_list.append(word)\n",
    "\n",
    "    word_list = preprocess_words(word_list)\n",
    "\n",
    "    labeled_data = list(zip(reviews, sentiments))\n",
    "\n",
    "    feature_sets = []\n",
    "\n",
    "    for review, sentiment in labeled_data:\n",
    "        feature = {}\n",
    "\n",
    "        check_words = word_tokenize(review)\n",
    "        check_words = preprocess_words(check_words)\n",
    "\n",
    "        for word in word_list:\n",
    "            feature[word] = word in check_words\n",
    "        \n",
    "        feature_sets.append((feature, sentiment))\n",
    "\n",
    "    random.shuffle(feature_sets)\n",
    "\n",
    "    train_count = int(len(feature_sets) * 0.8)\n",
    "    train_dataset = feature_sets[:train_count]\n",
    "    test_dataset = feature_sets[train_count:]\n",
    "\n",
    "    classifier = NaiveBayesClassifier.train(train_dataset)\n",
    "    print(f\"Accuracy: {accuracy(classifier, test_dataset) * 100 : ,.2f}%\")\n",
    "    \n",
    "    file = open('model.pickle', 'wb')\n",
    "    pickle.dump(classifier, file)\n",
    "    file.close()\n",
    "\n",
    "    return classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie recommendation based on reviews\n",
      "Your review: nice one\n",
      "Category: POSITIVE\n",
      "1. Enter review\n",
      "2. View movie recommendation\n",
      "3. View NER\n",
      "4. Exit\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "def print_menu():\n",
    "    global review\n",
    "    displayReview = \"No review\"\n",
    "\n",
    "    global category\n",
    "    displayCategory = \"None\"\n",
    "\n",
    "    if review != \"\":\n",
    "        displayReview = review\n",
    "\n",
    "    if category != \"\":\n",
    "        displayCategory = category\n",
    "\n",
    "    print(\"Movie recommendation based on reviews\")\n",
    "    print(f\"Your review: {displayReview}\")\n",
    "    print(f\"Category: {displayCategory}\")\n",
    "    print(\"1. Enter review\")\n",
    "    print(\"2. View movie recommendation\")\n",
    "    print(\"3. View NER\")\n",
    "    print(\"4. Exit\")\n",
    "    choice = input(\">> \")\n",
    "    return choice\n",
    "\n",
    "def write_review():\n",
    "    clear_output()\n",
    "\n",
    "    global review\n",
    "    global category\n",
    "    global classifier\n",
    "    print(\"Enter your review: \")\n",
    "    reviewInput = input(\">> \")\n",
    "\n",
    "    if len(reviewInput.split(' ')) < 20:\n",
    "        print(\"Review must be at least 20 words\")\n",
    "        enter_to_continue()\n",
    "        return\n",
    "\n",
    "    review = reviewInput\n",
    "\n",
    "    words = word_tokenize(reviewInput)\n",
    "    words = preprocess_words(words)\n",
    "\n",
    "    feature = FreqDist(words)\n",
    "    category = classifier.classify(feature)\n",
    "\n",
    "    print(f\"Review classified as: {category}\")\n",
    "    enter_to_continue()\n",
    "\n",
    "def view_movie_recommendation():\n",
    "    clear_output()\n",
    "\n",
    "    global review\n",
    "    df = load_dataset()\n",
    "\n",
    "    reviews = [str(review) for review in df['review'].to_list()]\n",
    "    titles = [str(title) for title in df['title'].to_list()]\n",
    "\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    matrix = vectorizer.fit_transform(reviews)\n",
    "\n",
    "    query_matrix = vectorizer.transform([review])\n",
    "    cosine_similarities = cosine_similarity(query_matrix, matrix).flatten()\n",
    "\n",
    "    related_docs_indices = cosine_similarities.argsort()[::-1][:3]\n",
    "\n",
    "    for i, idx in enumerate(related_docs_indices):\n",
    "        print(f\"{i+1}. {titles[idx]}\")\n",
    "    enter_to_continue()\n",
    "\n",
    "def view_ner():\n",
    "    clear_output()\n",
    "\n",
    "    df = load_dataset().sample(n=3000)\n",
    "    reviews = df['review'].to_string()\n",
    "\n",
    "    spacy_nlp = spacy.load('en_core_web_sm')\n",
    "    doc = spacy_nlp(reviews)\n",
    "\n",
    "    categories = {}\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        label = ent.label_\n",
    "\n",
    "        if label not in ['LANGUAGE', 'GPE']:\n",
    "            continue\n",
    "        \n",
    "        if label not in categories:\n",
    "            categories[label] = []\n",
    "        \n",
    "        categories[label].append(ent.text)\n",
    "\n",
    "    for label, entities in categories.items():\n",
    "        print(f\"{label}: {', '.join(entities)}\")\n",
    "\n",
    "    if len(categories) == 0:\n",
    "        print(\"No entities found\")\n",
    "\n",
    "    enter_to_continue()\n",
    "\n",
    "def main():\n",
    "    global classifier\n",
    "    try:\n",
    "        file = open('model.pickle', 'rb')\n",
    "        classifier = pickle.load(file)\n",
    "        file.close()\n",
    "    except FileNotFoundError:\n",
    "        classifier = train_model()\n",
    "    \n",
    "    while True:\n",
    "        clear_output()\n",
    "        choice = print_menu()\n",
    "        if choice == '1':\n",
    "            write_review()\n",
    "        elif choice == '2':\n",
    "            view_movie_recommendation()\n",
    "        elif choice == '3':\n",
    "            view_ner()\n",
    "        elif choice == '4':\n",
    "            break\n",
    "    \n",
    "    print(\"Goodbye!\")\n",
    "    \n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
